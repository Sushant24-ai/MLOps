{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d30132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f4ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 2.20.3\r\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f6c8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Homework_Path = os.getcwd()\n",
    "Data_Path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685818d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-20 06:57:08--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.239.238.119, 18.239.238.212, 18.239.238.133, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.239.238.119|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1427002 (1.4M) [binary/octet-stream]\n",
      "Saving to: â€˜green_tripdata_2023-01.parquet.3â€™\n",
      "\n",
      "green_tripdata_2023 100%[===================>]   1.36M  1.92MB/s    in 0.7s    \n",
      "\n",
      "2025-03-20 06:57:09 (1.92 MB/s) - â€˜green_tripdata_2023-01.parquet.3â€™ saved [1427002/1427002]\n",
      "\n",
      "--2025-03-20 06:57:10--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.239.238.119, 18.239.238.212, 18.239.238.133, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.239.238.119|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1533740 (1.5M) [binary/octet-stream]\n",
      "Saving to: â€˜green_tripdata_2023-02.parquet.3â€™\n",
      "\n",
      "green_tripdata_2023 100%[===================>]   1.46M  2.08MB/s    in 0.7s    \n",
      "\n",
      "2025-03-20 06:57:11 (2.08 MB/s) - â€˜green_tripdata_2023-02.parquet.3â€™ saved [1533740/1533740]\n",
      "\n",
      "--2025-03-20 06:57:11--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.239.238.133, 18.239.238.119, 18.239.238.152, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.239.238.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1730999 (1.7M) [binary/octet-stream]\n",
      "Saving to: â€˜green_tripdata_2023-03.parquet.3â€™\n",
      "\n",
      "green_tripdata_2023 100%[===================>]   1.65M  2.29MB/s    in 0.7s    \n",
      "\n",
      "2025-03-20 06:57:13 (2.29 MB/s) - â€˜green_tripdata_2023-03.parquet.3â€™ saved [1730999/1730999]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(Data_Path)\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet\n",
    "os.listdir()\n",
    "os.chdir(Homework_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780bae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r\n"
     ]
    }
   ],
   "source": [
    "ls -ltrh green*.parquet | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db87a41",
   "metadata": {},
   "source": [
    "Train a model with autolog - Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d69c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebc66b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:25:10</td>\n",
       "      <td>2023-03-01 00:35:47</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:14:29</td>\n",
       "      <td>2023-03-01 00:25:04</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:14:29</td>\n",
       "      <td>2023-03-01 00:25:04</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 22:59:46</td>\n",
       "      <td>2023-02-28 23:08:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:54:03</td>\n",
       "      <td>2023-03-01 01:03:14</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236</td>\n",
       "      <td>229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2023-03-01 00:25:10   2023-03-01 00:35:47                  N   \n",
       "1         2  2023-03-01 00:14:29   2023-03-01 00:25:04                  N   \n",
       "2         2  2023-03-01 00:14:29   2023-03-01 00:25:04                  N   \n",
       "3         2  2023-02-28 22:59:46   2023-02-28 23:08:38                  N   \n",
       "4         2  2023-03-01 00:54:03   2023-03-01 01:03:14                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            82           196              1.0           2.36   \n",
       "1         1.0             7             7              1.0           0.78   \n",
       "2         1.0             7             7              1.0           0.78   \n",
       "3         1.0           166            74              1.0           1.66   \n",
       "4         1.0           236           229              1.0           3.14   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         13.5    1.0      0.5        0.00           0.0        NaN   \n",
       "1         -6.5   -1.0     -0.5        0.00           0.0        NaN   \n",
       "2          6.5    1.0      0.5        0.00           0.0        NaN   \n",
       "3         11.4    1.0      0.5        2.78           0.0        NaN   \n",
       "4         15.6    1.0      0.5        4.17           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    1.0         16.00           2.0        1.0   \n",
       "1                   -1.0         -9.00           3.0        1.0   \n",
       "2                    1.0          9.00           3.0        1.0   \n",
       "3                    1.0         16.68           1.0        1.0   \n",
       "4                    1.0         25.02           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  0.00  \n",
       "2                  0.00  \n",
       "3                  0.00  \n",
       "4                  2.75  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"./green_tripdata_2023-01.parquet\"\n",
    "val_path = \"./green_tripdata_2023-02.parquet\"\n",
    "test_path = \"./green_tripdata_2023-03.parquet\"\n",
    "\n",
    "df_train = pd.read_parquet(train_path)\n",
    "df_val = pd.read_parquet(val_path)\n",
    "df_test = pd.read_parquet(test_path)\n",
    "\n",
    "df_train.head()\n",
    "df_val.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372ab9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def create_dataframe(filepath):\n",
    "    df = pd.read_parquet(train_path)\n",
    "    df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    df['pickup_day'] = df.lpep_pickup_datetime.apply(lambda x: x.weekday())\n",
    "    df['pickup_hour'] = df.lpep_pickup_datetime.apply(lambda x: x.hour)\n",
    "    df['pickup_min'] = df.lpep_pickup_datetime.apply(lambda x: x.minute)\n",
    "\n",
    "    \n",
    "    chosen_cols = ['duration','PULocationID','DOLocationID','trip_distance','pickup_day','pickup_hour','pickup_min']\n",
    "    df = df[chosen_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_dataframe(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "\n",
    "    numerical = ['trip_distance','pickup_day','pickup_hour','pickup_min']\n",
    "    \n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv\n",
    "\n",
    "def dump_pickle(obj, filename: str):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f4c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train contains: 65946 entries, and 5705 columns\n",
      "X_val contains: 65946 entries, and 5705 columns\n",
      "X_test contains: 65946 entries, and 5705 columns\n"
     ]
    }
   ],
   "source": [
    "dv = DictVectorizer()\n",
    "\n",
    "df_train = create_dataframe(train_path)\n",
    "df_val = create_dataframe(val_path)\n",
    "df_test = create_dataframe(test_path)\n",
    "\n",
    "X_train, dv = preprocess_dataframe(df_train,dv, fit_dv=True)\n",
    "X_val, _ = preprocess_dataframe(df_val,dv, fit_dv=False)\n",
    "X_test, _ = preprocess_dataframe(df_test,dv, fit_dv=False)\n",
    "\n",
    "print(f\"X_train contains: {np.shape(X_train)[0]} entries, and {np.shape(X_train)[1]} columns\")\n",
    "print(f\"X_val contains: {np.shape(X_val)[0]} entries, and {np.shape(X_val)[1]} columns\")\n",
    "print(f\"X_test contains: {np.shape(X_test)[0]} entries, and {np.shape(X_test)[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0878f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['duration']\n",
    "y_val = df_val['duration']\n",
    "y_test = df_test['duration']\n",
    "\n",
    "\n",
    "dump_pickle(dv, os.path.join(Data_Path, \"dv.pkl\"))\n",
    "dump_pickle((X_train, y_train), os.path.join(Data_Path, \"train.pkl\"))\n",
    "dump_pickle((X_val, y_val), os.path.join(Data_Path, \"val.pkl\"))\n",
    "dump_pickle((X_test, y_test), os.path.join(Data_Path, \"test.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc659320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:07:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "2025/03/20 07:07:53 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: When an mlflow-artifacts URI was supplied, the tracking URI must be a valid http or https URI, but it was currently set to file:///workspaces/MLOps/mlruns. Perhaps you forgot to set the tracking URI to the running MLflow server. To set the tracking URI, use either of the following methods:\n",
      "1. Set the MLFLOW_TRACKING_URI environment variable to the desired tracking URI. `export MLFLOW_TRACKING_URI=http://localhost:5000`\n",
      "2. Set the tracking URI programmatically by calling `mlflow.set_tracking_uri`. `mlflow.set_tracking_uri('http://localhost:5000')`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.877393542248552\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "data_path = \".\"\n",
    "\n",
    "X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run():\n",
    "    rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a815d",
   "metadata": {},
   "source": [
    "Launch the tracking server locally -Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65ae65c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/MLOps/mlruns/1', creation_time=1741584546996, experiment_id='1', last_update_time=1741584546996, lifecycle_stage='active', name='nyc-taxi-ride-prediction-single', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_uri = \"sqlite:///mlflow.db\"\n",
    "experiment_name = \"nyc-taxi-ride-prediction-single\"\n",
    "\n",
    "mlflow.set_tracking_uri(database_uri) \n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145ddcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e17bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhpo.py\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# or ['hpo.py', '--data_path', './output', '--num_trials', '15']\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Now call the Click command with standalone_mode=False to avoid automatic error handling\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandalone_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/click/core.py:1128\u001b[0m, in \u001b[0;36mBaseCommand.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;124;03m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/click/core.py:1053\u001b[0m, in \u001b[0;36mBaseCommand.main\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_context(prog_name, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[0;32m-> 1053\u001b[0m         rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m standalone_mode:\n\u001b[1;32m   1055\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/click/core.py:1395\u001b[0m, in \u001b[0;36mCommand.invoke\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m   1392\u001b[0m     echo(style(message, fg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m), err\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/click/core.py:754\u001b[0m, in \u001b[0;36mContext.invoke\u001b[0;34m(_Context__self, _Context__callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m augment_usage_errors(__self):\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__callback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mrun_optimization\u001b[0;34m(data_path, num_trials)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@click\u001b[39m\u001b[38;5;241m.\u001b[39mcommand()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@click\u001b[39m\u001b[38;5;241m.\u001b[39moption(\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--data_path\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_optimization\u001b[39m(data_path: \u001b[38;5;28mstr\u001b[39m, num_trials: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     X_val, y_val \u001b[38;5;241m=\u001b[39m load_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(params):\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mload_pickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pickle\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_in:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f_in)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/train.pkl'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Override sys.argv to only include the script name (or desired options)\n",
    "sys.argv = ['hpo.py']  # or ['hpo.py', '--data_path', './output', '--num_trials', '15']\n",
    "\n",
    "# Now call the Click command with standalone_mode=False to avoid automatic error handling\n",
    "run_optimization(standalone_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3715be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                         | 0/15 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:28:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:28:41 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpm9g0sv80/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run angry-ox-944 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/8938ac725cce4f558793b937d977a7f9                            \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      "  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                          | 1/15 [00:29<06:56, 29.78s/trial, best loss: 4.669037866079264]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:28:44 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:28:48 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpk4g6vira/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run redolent-sow-569 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/639d9048c1354f6d97d5bbb6f1a2dee3                        \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                     | 2/15 [00:35<03:23, 15.65s/trial, best loss: 4.669037866079264]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:28:50 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:28:54 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwux296it/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run adventurous-moth-985 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/17a8bfc6080e4f748e01d80a2119f9a8                    \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                | 3/15 [00:40<02:10, 10.83s/trial, best loss: 4.669037866079264]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:28:55 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:29:13 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpx5491bw9/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run stylish-asp-733 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/760be6c488cb4ab2889b851afb1cb1f7                         \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                          | 4/15 [00:59<02:35, 14.13s/trial, best loss: 4.545758317212148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:29:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:29:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpgkjcp2ap/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bemused-newt-974 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/3cd996c762e74f8b8915724c7682f586                        \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 5/15 [01:09<02:04, 12.40s/trial, best loss: 4.545758317212148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:29:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:29:53 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp8ri9wneq/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run angry-calf-3 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/422a42c4badc44cdbe46939cf52e867d                            \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                | 6/15 [01:40<02:48, 18.72s/trial, best loss: 4.404236426540846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:29:55 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:30:25 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmphiv10xmh/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run legendary-zebra-787 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/49e46fa4192b4997a7fba3419ce80e78                     \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                          | 7/15 [02:11<03:02, 22.85s/trial, best loss: 4.283608271051103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:30:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:30:30 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpqbjveabp/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run worried-chimp-619 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/cb50c23c5de44531a8bfe7a3ee139f0a                       \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                     | 8/15 [02:17<02:01, 17.42s/trial, best loss: 4.283608271051103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:30:32 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:30:49 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp1cv9rtwo/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run rambunctious-ox-898 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/d0f8725898f544c3825a0cd932f77bdf                     \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                | 9/15 [02:35<01:46, 17.75s/trial, best loss: 4.283608271051103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:30:50 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:31:06 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpom39hp9r/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bouncy-crane-742 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/9d8ce2319ff44985befab26133bb7d04                        \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 10/15 [02:52<01:27, 17.44s/trial, best loss: 4.283608271051103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:31:07 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:31:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpcbgyddoi/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bright-finch-448 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/103b9ad3ab804b1a80c2851c211804f7                        \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 11/15 [03:07<01:06, 16.68s/trial, best loss: 4.108006448090099]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:31:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:31:30 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpvprd2xbn/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run puzzled-jay-974 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/1d909d4064e647d8b6625655768fe62f                         \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 12/15 [03:16<00:43, 14.45s/trial, best loss: 4.108006448090099]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:31:31 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:31:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpyvrlp6w9/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run wise-bat-10 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/172410025dec4874acdc22f7cab9a9ae                             \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 13/15 [03:22<00:23, 11.79s/trial, best loss: 4.108006448090099]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:31:37 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:31:49 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpito1n8me/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run rambunctious-ram-599 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/80369df144b04cf29755d6649361ade8                    \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/15 [03:35<00:12, 12.29s/trial, best loss: 4.108006448090099]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 07:31:51 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "\n",
      "2025/03/20 07:32:09 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpyr66a4ov/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run overjoyed-steed-139 at: http://127.0.0.1:5000/#/experiments/655456287014535769/runs/81d59ed7e5ce4445a1a2231af000a17e                     \n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/655456287014535769                                                                        \n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [03:55<00:00, 15.70s/trial, best loss: 4.108006448090099]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import click\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def run_optimization(data_path=\".\", num_trials=15):\n",
    "\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "    def objective(params):\n",
    "        # Start a nested MLflow run to log each hyperopt trial\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.log_params(params)\n",
    "            \n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_val)\n",
    "            rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "            \n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            \n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rstate = np.random.default_rng(42)  # for reproducibility\n",
    "    fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=Trials(),\n",
    "        rstate=rstate\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_optimization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62305b",
   "metadata": {},
   "source": [
    "Q6 Promote the best model to the model registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01441352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow.sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ed1fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename: str):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "test_data_path = \".\"  \n",
    "X_test, y_test = load_pickle(os.path.join(test_data_path, \"test.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d047e05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 10:04:30 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-best-model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/576275541145509561', creation_time=1742465070564, experiment_id='576275541145509561', last_update_time=1742465070564, lifecycle_stage='active', name='random-forest-best-model', tags={}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "experiment_name = \"random-forest-best-model\"\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f083e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file '/workspaces/MLOps/mlruns/1/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 328, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 422, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1368, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1361, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 310, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/workspaces/MLOps/mlruns/1/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using experiment id: 655456287014535769\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    # Create the experiment if it doesn't exist.\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "print(\"Using experiment id:\", experiment_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a00d5d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file '/workspaces/MLOps/mlruns/1/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 328, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 422, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1368, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1361, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 310, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/workspaces/MLOps/mlruns/1/meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '1'. Detailed error Yaml file '/workspaces/MLOps/mlruns/1/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 328, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 422, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1368, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py\", line 1361, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/mlflow/utils/file_utils.py\", line 310, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/workspaces/MLOps/mlruns/1/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using experiment id: 655456287014535769\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"random-forest-hyperopt\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    # Create experiment if it doesn't exist.\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "print(\"Using experiment id:\", experiment_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c3eca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"metrics.rmse >= 0\",\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    max_results=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae47f062",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:5000/#/experiments/655456287014535769/model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the model from MLflow\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Predict on the test set and compute RMSE\u001b[39;00m\n\u001b[1;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mlflow/sklearn/__init__.py:633\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, dst_path)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_uri, dst_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    Load a scikit-learn model from a local file or a run.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m        predictions = sk_model.predict(pandas_df)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m     local_model_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     flavor_conf \u001b[38;5;241m=\u001b[39m _get_flavor_configuration(model_path\u001b[38;5;241m=\u001b[39mlocal_model_path, flavor_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME)\n\u001b[1;32m    635\u001b[0m     _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mlflow/tracking/artifact_utils.py:116\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[1;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[1;32m    115\u001b[0m     )\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repo.py:280\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Submit download tasks\u001b[39;00m\n\u001b[1;32m    279\u001b[0m futures \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_artifacts_recursive(artifact_path):\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_info\u001b[38;5;241m.\u001b[39mis_dir:  \u001b[38;5;66;03m# Empty directory\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repo.py:179\u001b[0m, in \u001b[0;36mArtifactRepository._is_directory\u001b[0;34m(self, artifact_path)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_directory\u001b[39m(\u001b[38;5;28mself\u001b[39m, artifact_path):\n\u001b[0;32m--> 179\u001b[0m     listing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(listing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mlflow/store/artifact/http_artifact_repo.py:84\u001b[0m, in \u001b[0;36mHttpArtifactRepository.list_artifacts\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     83\u001b[0m     endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mlflow-artifacts/artifacts\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 84\u001b[0m     url, tail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_uri\u001b[38;5;241m.\u001b[39msplit(endpoint, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     85\u001b[0m     root \u001b[38;5;241m=\u001b[39m tail\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: posixpath\u001b[38;5;241m.\u001b[39mjoin(root, path) \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;28;01melse\u001b[39;00m root}\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "best_rmse = float(\"inf\")\n",
    "best_run_id = None\n",
    "\n",
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"http://127.0.0.1:5000/#/experiments/655456287014535769/model\"\n",
    "    \n",
    "    # Load the model from MLflow\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    # Predict on the test set and compute RMSE\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"Run ID: {run_id}, Test RMSE: {rmse_test}\")\n",
    "    \n",
    "    if rmse_test < best_rmse:\n",
    "        best_rmse = rmse_test\n",
    "        best_run_id = run_id\n",
    "\n",
    "print(\"Best run ID:\", best_run_id)\n",
    "print(\"Best test RMSE:\", best_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5dc50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 10:12:50 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "2025/03/20 10:13:05 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpu7hsvd4t/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run painted-bear-697 at: http://127.0.0.1:5000/#/experiments/472326644643157653/runs/3d2f9ae98ab1418e8cb1590b0fcd0865\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/472326644643157653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 10:13:10 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "2025/03/20 10:13:29 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpzh8kt6u4/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bedecked-lynx-842 at: http://127.0.0.1:5000/#/experiments/472326644643157653/runs/271c15a1a8de4371a7ac993a9b7cc808\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/472326644643157653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 10:13:32 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "2025/03/20 10:14:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp_ej_buoj/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run respected-ape-72 at: http://127.0.0.1:5000/#/experiments/472326644643157653/runs/c1b98d821e654798abb859376f6ddd2b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/472326644643157653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 10:14:05 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "2025/03/20 10:14:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpjeyp8imz/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bouncy-shoat-359 at: http://127.0.0.1:5000/#/experiments/472326644643157653/runs/b25e5fc7310b4cc1b55d3292953e7d2f\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/472326644643157653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 10:14:20 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n",
      "2025/03/20 10:14:50 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpe8t92vii/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.0.2', 'cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "Successfully registered model 'RandomForest_Best_Model'.\n",
      "2025/03/20 10:14:52 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: RandomForest_Best_Model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run gregarious-cod-528 at: http://127.0.0.1:5000/#/experiments/472326644643157653/runs/170ec091d9c4461b9870688040deee41\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/472326644643157653\n",
      "Best run ID: 3d2f9ae98ab1418e8cb1590b0fcd0865\n",
      "Best test RMSE: 4.108006448090099\n",
      "Model registered as: RandomForest_Best_Model\n",
      "Registered model version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'RandomForest_Best_Model'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import click\n",
    "import mlflow\n",
    "\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Experiment names\n",
    "HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
    "BEST_MODEL_EXPERIMENT_NAME = \"random-forest-best-models\"\n",
    "# Only include these RF hyperparameters from the run's parameters\n",
    "RF_PARAMS = ['max_depth', 'n_estimators', 'min_samples_split', 'min_samples_leaf', 'random_state']\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(BEST_MODEL_EXPERIMENT_NAME)\n",
    "mlflow.sklearn.autolog()  # autologging enabled for this experiment\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "def train_and_log_model(data_path, params):\n",
    "    # Load training, validation, and test datasets\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
    "\n",
    "    # Filter parameters to only those in RF_PARAMS and cast them to int\n",
    "    filtered_params = {}\n",
    "    for param in RF_PARAMS:\n",
    "        if param in params:\n",
    "            try:\n",
    "                filtered_params[param] = int(params[param])\n",
    "            except ValueError:\n",
    "                # if conversion to int fails, try float or use as is\n",
    "                try:\n",
    "                    filtered_params[param] = float(params[param])\n",
    "                except ValueError:\n",
    "                    filtered_params[param] = params[param]\n",
    "    # Start an MLflow run for this training\n",
    "    with mlflow.start_run():\n",
    "        rf = RandomForestRegressor(**filtered_params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on the validation set and log the metric\n",
    "        val_rmse = mean_squared_error(y_val, rf.predict(X_val), squared=False)\n",
    "        mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "        # Evaluate on the test set and log the metric\n",
    "        test_rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "        # The trained model is also logged (via autolog)\n",
    "\n",
    "\n",
    "def run_register_model(data_path=\".\", top_n=5):\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Retrieve the hyperopt experiment by name\n",
    "    hpo_experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    if hpo_experiment is None:\n",
    "        raise Exception(f\"Experiment '{HPO_EXPERIMENT_NAME}' not found.\")\n",
    "    \n",
    "    # Get the top_n runs sorted by rmse (lowest first) from the hyperopt experiment\n",
    "    hpo_runs = client.search_runs(\n",
    "        experiment_ids=[hpo_experiment.experiment_id],\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=top_n,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "    if not hpo_runs:\n",
    "        raise Exception(\"No runs found in the hyperopt experiment.\")\n",
    "\n",
    "    # For each of the top_n hyperopt runs, retrain the model with those parameters\n",
    "    # and log results into the best-models experiment.\n",
    "    for run in hpo_runs:\n",
    "        # Use only the desired parameters from the run\n",
    "        run_params = {k: v for k, v in run.data.params.items() if k in RF_PARAMS}\n",
    "        train_and_log_model(data_path=data_path, params=run_params)\n",
    "\n",
    "    # Now search in the BEST_MODEL_EXPERIMENT_NAME for the run with the lowest test RMSE\n",
    "    best_experiment = client.get_experiment_by_name(BEST_MODEL_EXPERIMENT_NAME)\n",
    "    best_runs = client.search_runs(\n",
    "        experiment_ids=[best_experiment.experiment_id],\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        order_by=[\"metrics.test_rmse ASC\"],\n",
    "        max_results=1\n",
    "    )\n",
    "    if not best_runs:\n",
    "        raise Exception(\"No runs found in the best-models experiment.\")\n",
    "\n",
    "    best_run = best_runs[0]\n",
    "    best_run_id = best_run.info.run_id\n",
    "    best_test_rmse = best_run.data.metrics[\"test_rmse\"]\n",
    "\n",
    "    print(\"Best run ID:\", best_run_id)\n",
    "    print(\"Best test RMSE:\", best_test_rmse)\n",
    "\n",
    "    # Register the best model to the model registry.\n",
    "    model_uri = f\"runs:/{best_run_id}/model\"\n",
    "    model_name = \"RandomForest_Best_Model\"\n",
    "    registered_model = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "    print(\"Model registered as:\", registered_model.name)\n",
    "    print(\"Registered model version:\", registered_model.version)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_register_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ca91d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
