{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91e35945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712a2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Homework_Path = os.getcwd()\n",
    "Data_Path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e7679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-08 10:55:19--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.164.82.112, 3.164.82.160, 3.164.82.40, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.164.82.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1427002 (1.4M) [binary/octet-stream]\n",
      "Saving to: ‘green_tripdata_2023-01.parquet’\n",
      "\n",
      "green_tripdata_2023 100%[===================>]   1.36M  2.30MB/s    in 0.6s    \n",
      "\n",
      "2025-03-08 10:55:21 (2.30 MB/s) - ‘green_tripdata_2023-01.parquet’ saved [1427002/1427002]\n",
      "\n",
      "--2025-03-08 10:55:21--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.164.82.197, 3.164.82.112, 3.164.82.40, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.164.82.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1533740 (1.5M) [binary/octet-stream]\n",
      "Saving to: ‘green_tripdata_2023-02.parquet’\n",
      "\n",
      "green_tripdata_2023 100%[===================>]   1.46M  2.33MB/s    in 0.6s    \n",
      "\n",
      "2025-03-08 10:55:23 (2.33 MB/s) - ‘green_tripdata_2023-02.parquet’ saved [1533740/1533740]\n",
      "\n",
      "--2025-03-08 10:55:23--  https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 3.164.82.197, 3.164.82.40, 3.164.82.112, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|3.164.82.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1730999 (1.7M) [binary/octet-stream]\n",
      "Saving to: ‘green_tripdata_2023-03.parquet’\n",
      "\n",
      "green_tripdata_2023 100%[===================>]   1.65M  2.61MB/s    in 0.6s    \n",
      "\n",
      "2025-03-08 10:55:24 (2.61 MB/s) - ‘green_tripdata_2023-03.parquet’ saved [1730999/1730999]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(Data_Path)\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-03.parquet\n",
    "os.listdir()\n",
    "os.chdir(Homework_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87ec7749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:25:10</td>\n",
       "      <td>2023-03-01 00:35:47</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:14:29</td>\n",
       "      <td>2023-03-01 00:25:04</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:14:29</td>\n",
       "      <td>2023-03-01 00:25:04</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-28 22:59:46</td>\n",
       "      <td>2023-02-28 23:08:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-01 00:54:03</td>\n",
       "      <td>2023-03-01 01:03:14</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236</td>\n",
       "      <td>229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2023-03-01 00:25:10   2023-03-01 00:35:47                  N   \n",
       "1         2  2023-03-01 00:14:29   2023-03-01 00:25:04                  N   \n",
       "2         2  2023-03-01 00:14:29   2023-03-01 00:25:04                  N   \n",
       "3         2  2023-02-28 22:59:46   2023-02-28 23:08:38                  N   \n",
       "4         2  2023-03-01 00:54:03   2023-03-01 01:03:14                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            82           196              1.0           2.36   \n",
       "1         1.0             7             7              1.0           0.78   \n",
       "2         1.0             7             7              1.0           0.78   \n",
       "3         1.0           166            74              1.0           1.66   \n",
       "4         1.0           236           229              1.0           3.14   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         13.5    1.0      0.5        0.00           0.0        NaN   \n",
       "1         -6.5   -1.0     -0.5        0.00           0.0        NaN   \n",
       "2          6.5    1.0      0.5        0.00           0.0        NaN   \n",
       "3         11.4    1.0      0.5        2.78           0.0        NaN   \n",
       "4         15.6    1.0      0.5        4.17           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    1.0         16.00           2.0        1.0   \n",
       "1                   -1.0         -9.00           3.0        1.0   \n",
       "2                    1.0          9.00           3.0        1.0   \n",
       "3                    1.0         16.68           1.0        1.0   \n",
       "4                    1.0         25.02           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  0.00  \n",
       "2                  0.00  \n",
       "3                  0.00  \n",
       "4                  2.75  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"./green_tripdata_2023-01.parquet\"\n",
    "val_path = \"./green_tripdata_2023-02.parquet\"\n",
    "test_path = \"./green_tripdata_2023-03.parquet\"\n",
    "\n",
    "df_train = pd.read_parquet(train_path)\n",
    "df_val = pd.read_parquet(val_path)\n",
    "df_test = pd.read_parquet(test_path)\n",
    "\n",
    "df_train.head()\n",
    "df_val.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b7c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def create_dataframe(filepath):\n",
    "    df = pd.read_parquet(train_path)\n",
    "    df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    df['pickup_day'] = df.lpep_pickup_datetime.apply(lambda x: x.weekday())\n",
    "    df['pickup_hour'] = df.lpep_pickup_datetime.apply(lambda x: x.hour)\n",
    "    df['pickup_min'] = df.lpep_pickup_datetime.apply(lambda x: x.minute)\n",
    "\n",
    "    \n",
    "    chosen_cols = ['duration','PULocationID','DOLocationID','trip_distance','pickup_day','pickup_hour','pickup_min']\n",
    "    df = df[chosen_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_dataframe(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "\n",
    "    numerical = ['trip_distance','pickup_day','pickup_hour','pickup_min']\n",
    "    \n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv\n",
    "\n",
    "def dump_pickle(obj, filename: str):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9f2227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train contains: 65946 entries, and 5705 columns\n",
      "X_val contains: 65946 entries, and 5705 columns\n",
      "X_test contains: 65946 entries, and 5705 columns\n"
     ]
    }
   ],
   "source": [
    "dv = DictVectorizer()\n",
    "\n",
    "df_train = create_dataframe(train_path)\n",
    "df_val = create_dataframe(val_path)\n",
    "df_test = create_dataframe(test_path)\n",
    "\n",
    "X_train, dv = preprocess_dataframe(df_train,dv, fit_dv=True)\n",
    "X_val, _ = preprocess_dataframe(df_val,dv, fit_dv=False)\n",
    "X_test, _ = preprocess_dataframe(df_test,dv, fit_dv=False)\n",
    "\n",
    "print(f\"X_train contains: {np.shape(X_train)[0]} entries, and {np.shape(X_train)[1]} columns\")\n",
    "print(f\"X_val contains: {np.shape(X_val)[0]} entries, and {np.shape(X_val)[1]} columns\")\n",
    "print(f\"X_test contains: {np.shape(X_test)[0]} entries, and {np.shape(X_test)[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a72eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['duration']\n",
    "y_val = df_val['duration']\n",
    "y_test = df_test['duration']\n",
    "\n",
    "\n",
    "dump_pickle(dv, os.path.join(Data_Path, \"dv.pkl\"))\n",
    "dump_pickle((X_train, y_train), os.path.join(Data_Path, \"train.pkl\"))\n",
    "dump_pickle((X_val, y_val), os.path.join(Data_Path, \"val.pkl\"))\n",
    "dump_pickle((X_test, y_test), os.path.join(Data_Path, \"test.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464ff996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/MLOps/experiment-tracking-02/mlruns/1', creation_time=1741431460219, experiment_id='1', last_update_time=1741431460219, lifecycle_stage='active', name='nyc-taxi-ride-prediction-single', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_uri = \"sqlite:///mlflow.db\"\n",
    "experiment_name = \"nyc-taxi-ride-prediction-single\"\n",
    "\n",
    "mlflow.set_tracking_uri(database_uri) \n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62be8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"developer\",\"Marcus\")\n",
    "    mlflow.log_param(\"train-data-path\",train_path)\n",
    "    mlflow.log_param(\"val-data-path\",val_path)\n",
    "\n",
    "    params = {\n",
    "        'max_depth': 15,\n",
    "        'n_estimators': 50,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\",rmse)\n",
    "\n",
    "    \n",
    "    with open('./rf_reg.bin','wb') as f_out:\n",
    "        pickle.dump((dv,rf), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e03a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/08 11:03:42 INFO mlflow.tracking.fluent: Experiment with name 'nyc-taxi-ride-prediction-optimisation' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/MLOps/experiment-tracking-02/mlruns/2', creation_time=1741431822639, experiment_id='2', last_update_time=1741431822639, lifecycle_stage='active', name='nyc-taxi-ride-prediction-optimisation', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_uri = \"sqlite:///mlflow.db\"\n",
    "experiment_name = \"nyc-taxi-ride-prediction-optimisation\"\n",
    "\n",
    "mlflow.set_tracking_uri(database_uri) \n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8054cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials    \n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 100, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 20, 1)),\n",
    "        'criterion' : hp.choice('criterion', ['squared_error', 'poisson']),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 10, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\",\"RandomForestRegressor\")\n",
    "        mlflow.set_tag(\"developer\",\"Marcus\")\n",
    "        mlflow.log_param(\"train-data-path\",train_path)\n",
    "        mlflow.log_param(\"val-data-path\",val_path)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        \n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\",rmse)\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e2f20d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 855 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /home/codespace/anaconda3/lib/python3.9/site-packages (from hyperopt) (2.7.1)\n",
      "Requirement already satisfied: six in /home/codespace/anaconda3/lib/python3.9/site-packages (from hyperopt) (1.16.0)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "\u001b[K     |████████████████████████████████| 203 kB 76.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/codespace/anaconda3/lib/python3.9/site-packages (from hyperopt) (1.21.5)\n",
      "Requirement already satisfied: tqdm in /home/codespace/anaconda3/lib/python3.9/site-packages (from hyperopt) (4.64.0)\n",
      "Requirement already satisfied: cloudpickle in /home/codespace/anaconda3/lib/python3.9/site-packages (from hyperopt) (2.0.0)\n",
      "Requirement already satisfied: future in /home/codespace/anaconda3/lib/python3.9/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: scipy in /home/codespace/anaconda3/lib/python3.9/site-packages (from hyperopt) (1.7.3)\n",
      "Installing collected packages: py4j, hyperopt\n",
      "Successfully installed hyperopt-0.2.7 py4j-0.10.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "857f6833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [42:07<00:00, 25.28s/trial, best loss: 3.9843860803819906]\n"
     ]
    }
   ],
   "source": [
    "rstate = np.random.default_rng(42)\n",
    "\n",
    "best_result = fmin(\n",
    "    fn = objective,\n",
    "    space = search_space, \n",
    "    algo = tpe.suggest, \n",
    "    max_evals = 100,\n",
    "    trials = Trials(), \n",
    "    rstate=rstate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec42b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
